\documentclass{beamer}
\usepackage{ferres}
\usepackage{caption}
\usepackage{subcaption}
\framelogo{img/msu-logo}
\usepackage[OT2,T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[russian,english]{babel}

%math
\input{math_commands.tex}
\author{Максим Кочуров}
\title[Прикладные байесовские методы]{Байесовское моделирование }
\institute[МГУ]{МГУ им. М.В. Ломоносова}
\date{Лекция 2}
\usepackage{caption} % Кастомные названия объектов
\captionsetup[figure]{name=Рис.} %тут можно вписать много опций, но я оставил только касающуюся вопроса

% Начало документа 
\begin{document}
\begin{frame}
	\maketitle
\end{frame}
\begin{frame}{Содержание}
\tableofcontents
\end{frame}
\section{HMC}
\begin{frame}{Сэмплирование из распределения}
    \begin{columns}[t]
    \begin{column}{0.5\linewidth}
    Сопряженные модели
    \begin{itemize}
        \item Ограниченная применимость
        \item Недостаточная гибкость
        \item Хорошая масштабируемость
    \end{itemize}
    \begin{figure}
        \centering
        \includegraphics[width=0.7\linewidth]{img/normal-distribution}
        \caption{Простое распределение}
    \end{figure}
    \end{column}
    \begin{column}{0.5\linewidth}
    Большинство моделей
    \begin{itemize}
        \item Нет аналитического решения
        \item Апостериорные распределения сложные 
        \item Плохая масштабируемость
        \item Гибкость
    \end{itemize}
    \begin{figure}
        \centering
        \includegraphics[width=0.7\linewidth]{img/zigzag-distribution}
        \caption{Сложное распределение}
    \end{figure}
    \end{column}
    \end{columns}
\end{frame}
\begin{frame}{Метод Монте-Карло с механикой Гамильтона (HMC)}
\begin{columns}
\begin{column}{0.5\linewidth}
В HMC сэмплирование происходит из сложных распределений
\begin{enumerate}
    \item Берем идеи из физики
    \item Считаем градиенты
    \item Численно интегрируем
\end{enumerate}
Откалиброванная модель HMC сходится к целевому распределению
\begin{alertblock}{Предупреждение}
Мы обещали курс без сложной математики. Но HMC нужен для отладки ваших моделей.
\end{alertblock}
\end{column}
\begin{column}{0.5\linewidth}
\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{img/funnel_leapfrog}
    \captionsetup{justification=centering}
    \caption{интегрирование методом Leapfrog}
    % \label{fig:my_label}
\end{figure}
\end{column}
\end{columns}
\end{frame}
\begin{frame}{Построение распределений через HMC}
\begin{columns}
\begin{column}{0.5\linewidth}
\begin{itemize}
    \item $p(\Theta)$ - Целевое распределение, $\Theta \in \sR^d$ ($\Theta$ или \textbf{Координаты})
    \item $p(\Delta\cond\Theta)$ - Распределение импульса, $\Delta \in \sR^d$ \\($\Delta$ или \textbf{Ускорение})
\end{itemize}
Гамильтониан вычисляется как
\begin{equation*}
 H(\Delta, \Theta) = -\log p(\Delta, \Theta)   
\end{equation*}
\begin{block}{Заметка}
\begin{itemize}
    \item $p(\Delta\cond\Theta) = \operatorname{Normal}(0, M)$
    \item $\Delta$ и $\Theta$ имеют одинаковые размерности
\end{itemize}

\end{block}
\end{column}
\begin{column}{0.5\linewidth}
\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{img/normal-histogram}
    \caption{$p(\Theta) = \operatorname{Normal}(0, 1)$}
\end{figure}
\end{column}
\end{columns}
\end{frame}

\begin{frame}{Система дифференциальных уровнений HMC}
\begin{columns}
\begin{column}{0.5\linewidth}
\begin{align*}
    H(\Delta, \Theta) &= -\log p(\Delta, \Theta)\\
    &=-\log p(\Delta\cond\Theta) &-\log p(\Theta)\\
    &=\underbrace{K(\Delta, \Theta)}_{\text{Kinetic E}} &+  \underbrace{V(\Theta)}_{\text{Potential E}}
\end{align*}
Физическая система, задающая \textbf{движение} 
\begin{align*}
    \frac{\partial \Theta}{\partial t} &= \frac{\partial H}{\partial \Delta}\\
    \frac{\partial \Delta}{\partial t} &= -\frac{\partial H}{\partial \Theta}
\end{align*}
\textbf{Движение} содержит полную энергию $H(\Delta, \Theta)$
\end{column}
\begin{column}{0.5\linewidth}
\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{img/scateboard}
    \caption{скейт-парк и HMC}
\end{figure}
\end{column}
\end{columns}
\end{frame}
\begin{frame}{Дивергенции в HMC}
Дивергенции возникают при крупной ошибке численного интегрирования в ходе решения дифференциального уравнения.
    \begin{alertblock}{Когда HMC не работает}
    Неудачный выбор геометрического распределения вероятностей для гамильтнониана 
    \end{alertblock}
Почему геометрическое распределение неудачно
\begin{columns}[t]
\begin{column}{0.5\linewidth}
\begin{enumerate}
    \item Мультиколлинеарность
    \item Распределения вида воронки
    \item Сильное влияние функции правдоподобия
    \item Неоднородное апостериорные распределение 
\end{enumerate}
\end{column}
\begin{column}{0.5\linewidth}
\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{img/funnel_1}
    \caption{Воронка Нила}
\end{figure}
\end{column}
\end{columns}

\end{frame}
\begin{frame}{Что почитать по HMC}
\begin{alertblock}{Для дальнейшего погружения}
\begin{enumerate}
    \item Интерактивное \href{https://chi-feng.github.io/mcmc-demo/app.html}{демо}
    \item \href{https://colindcarroll.com/2019/04/11/hamiltonian-monte-carlo-from-scratch/}{Пособие} от Colin Carrol
    \item \href{https://arxiv.org/abs/1701.02434}{Статья} Michael Betancourt
    \item \href{https://arxiv.org/abs/1111.4246}{Статья} про NUTS от Matthew D. Hoffman, Andrew Gelman
\end{enumerate}
\end{alertblock}
\end{frame}
\section{Модель Кобба-Дугласа}
\begin{frame}{}
    \centering \Huge Пример
\end{frame}

\begin{frame}{Простой пример - функция Кобба-Дугласа}
\begin{columns}
\begin{column}{0.5\linewidth}
Скорее всего, вы знакомы с производственной функцией вида
\begin{equation*}
    Y \approx A \cdot L ^ \beta
\end{equation*}
Имеем:
\begin{enumerate}
    \item 6 различных групп (иерархия)
    \item Группы различимы
    \item Мы знаем, что факторная производительность $A$ различается между ними
    \item Производительность труда $\beta$ различается не сильно
\end{enumerate}
\end{column}
\begin{column}{0.5\linewidth}
\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{img/example-cobb-douglas-pooled}
    \caption{Пример агрегированных данных}
\end{figure}
\end{column}
\end{columns}
\end{frame}
\begin{frame}{Простой пример - производство ковров}
\begin{columns}
\begin{column}{0.5\linewidth}
Уточним пример
\begin{equation*}
    Y_g \approx A_g \cdot L ^ \beta
\end{equation*}
Пусть есть ателье, шьющее ковры, с 6 рабочими:
\begin{enumerate}
    \item Работники делают разные ковры с различной факторной производительностью $A$
    \item Производительность труда $\beta$ можно воспринимать как сосредоточенность, со временем работники устают
    \item Работник шьет ковер один, без чужой помощи
\end{enumerate}
\end{column}
\begin{column}{0.5\linewidth}
\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{img/carpet-photo}
    \caption{Пример продукта (Y)}
\end{figure}
\end{column}
\end{columns}
\end{frame}
\begin{frame}{Парадокс Симпсона}
    \begin{figure}
    \centering
        \begin{subfigure}[l]{0.45\linewidth}
             \centering
             \includegraphics[width=\linewidth]{img/example-cobb-douglas-pooled-reg}
         \end{subfigure}
         \begin{subfigure}[r]{0.5\linewidth}
             \centering
             \includegraphics[width=\linewidth]{img/example-cobb-douglas-reg}
         \end{subfigure}
    \end{figure}
\end{frame}
\section{Базовая модель}
\subsection{Настройка}
\begin{frame}{Модель с одной группой}
    Несколько советов для моделирования.
    \begin{itemize}
        \item Начинать стоит с простой модели
        \visible<2->{
        \begin{itemize}
            \item Рассмотрите модель с 1 группой
            \item Проверьте, что априорные распределения выбраны корректно
        \end{itemize}
        }
        \item Убедитесь, что модель сходится
        \visible<3->{
        \begin{itemize}
            \item Если не сойдется модель с одной группой -- модели с множеством групп тоже не сойдутся
            \item Проведите проверку, что модель семплируется корректно
        \end{itemize}
        }
        \item Усложните модель
        \visible<4->{
        \begin{itemize}
            \item Попробуйте сделать параметризацию
            \item Проверьте семплирование модели
            \item Сравните модели (про это -- поговорим далее по курсу)
        \end{itemize}
        }
    \end{itemize}
\end{frame}
\subsection{Априорные распределения}
\begin{frame}{Простая модель: с чего начать?}
    Для начала зададим себе несколько вопросов
    \begin{equation*}
    Y_{g=0} \approx A_{g=0} \cdot L ^ \beta
\end{equation*}
\begin{enumerate}
    \item Какое апостериорное распределение взять для $A$?
    \item Какое апостериорное распределение взять для $\beta$?
    \item Какое апостериорное предиктивное распределение для $Y_{g=0}$?
\end{enumerate}
\end{frame}
\begin{frame}{Формулируем модель}
    \begin{align*}
        Y_{g=0} &\approx A_{g=0} \cdot L ^ \beta\\
        \log Y_{g=0} &\approx \log A_{g=0} + \log L \cdot \beta\\
    \end{align*}
    Предполагаем следующие распределения
    \begin{align*}
        \log Y_{g=0} &\sim \operatorname{Normal}(\log A_{g=0} + \log L \cdot \beta, \eps)\\
        \eps &\sim \text{???}\\
        \beta &\sim \text{???}\\
        A_{g=0} &\sim \text{???}\\
    \end{align*}
\end{frame}
\begin{frame}{Априорное распределение для $\beta$}
    Какие свойства мы предполагаем для производительности (или эластичности) труда $\beta$? Подумайте
    \begin{enumerate}
        \item Может ли она быть $<0$? \visible<2->{Нет}
        \item Может ли она принимать большие значения? \visible<3->{Нет}
        \item Может ли она быть $>1$? \visible<4->{Нет}
    \end{enumerate}
    \visible<5->{Заключение: она лежит в промежутке $(0, 1)$
    \begin{block}{Данные априорные предположения -- субъективны!}
    Есть у кого-то замечания по нашим ограничениям?
    \end{block}}
    \visible<6->{
    \begin{alertblock}{Мы пока еще не вывели априорное распределение}
    Нужно подобрать распределение, которое удовлетворяет нашим условиям
    \end{alertblock}}
\end{frame}
\begin{frame}{Априорное распределение для $\beta$}
    Что имеем: 
    \begin{itemize}
        \item $\beta \in (0, 1)$
        \item Маловероятно, что истинное значение близко к границам
        \item Ничего не знаем о том, где конкретно в интервале оно лежит.
    \end{itemize}
\begin{block}{Заметка}
Посмотрим распределения, которые удовлетворяют требованиям
\end{block}
\begin{enumerate}
    \item<2-> $\operatorname{Beta}(a, b),\; a>0, b > 0$ где $a, b$ удовлетворяют ограничениям
    \item<3-> $\operatorname{LogitNormal}(\mu, \sigma)$ - всегда удовлетворяет ограничениям
    \item<4-> $\operatorname{Uniform}(0, 1)$ - частный случай $\operatorname{Beta}(1, 1)$
    \item<5-> $\operatorname{Kumaraswamy}(a, b),\; a>0, b > 0$ но лучше обойтись без него
\end{enumerate}
\end{frame}
\begin{frame}{Визуализируем априорное распределение}
Перед написанием изобразите распределения. Какое лучше?
\begin{figure}
    \centering
    \includegraphics[width=.6\linewidth]{img/priors-beta}
    \caption{Распределения с прошлого слайда}
\end{figure}
Выбирайте то, которое нравится и согласуется с теорией
\end{frame}
\begin{frame}{Настраиваем априорное распределение}
    Для этой задачи я выберу $\operatorname{LogitNormal}(0, 1)$. У него удобная функциональная форма
    \begin{block}{Помните}
    \begin{itemize}
        \item Априорное распределение при моделировании выбираете \textbf{вы}
        \item Этот выбор должен быть обоснован
        \item Выбор должен быть разумным, учитывать накопленное знание
        \item Вы должны иметь возможность защитить свой выбор
        \item \textbf{Априорное распределение -- источник неопределенности}
    \end{itemize}
    \end{block}
\end{frame}
\begin{frame}{Простая модель: что имеем на данный момент}
    \begin{align*}
        \log Y_{g=0} &\sim \operatorname{Normal}(\log A_{g=0} + \log L \cdot \beta, \eps)\\
        \eps &\sim \text{???}\\
        \beta &\sim \operatorname{LogitNormal}(0, 1)\\
        A_{g=0} &\sim \text{???}\\
    \end{align*}
\end{frame}
\begin{frame}{Априорное распределение $\eps$}
    \begin{block}{Эмпирическое наблюдение}
    Ошибка обычно не велика. Но при этом не равна нулю.
    \end{block}
    \begin{columns}
    \begin{column}{0.5\linewidth}
    В нашем случае;
    \begin{itemize}
        \item ''маленькая ошибка'' означает отклонение в 10-50\%
    \end{itemize}
    Пусть
    \begin{equation*}
        \eps \sim \operatorname{LogNormal}(-2, 1)
    \end{equation*}
    \visible<2->{
    \begin{block}{Примечание}
        В логарифмических моделях ошибка -- величина относительная
    \end{block}
    }
    \end{column}
    \begin{column}{0.5\linewidth}
    \begin{figure}
        \centering
        \includegraphics[width=\linewidth]{img/priors-e}
        \caption{Априорное распределение для $\eps$}
    \end{figure}
    \end{column}
    \end{columns}
\end{frame}
\begin{frame}{Простая модель: что имеем на данный момент}
    \begin{align*}
        \log Y_{g=0} &\sim \operatorname{Normal}(\log A_{g=0} + \log L \cdot \beta, \eps)\\
        \eps &\sim \operatorname{LogNormal}(-2, 1)\\
        \beta &\sim \operatorname{LogitNormal}(0, 1)\\
        A_{g=0} &\sim \text{???}\\
    \end{align*}
\end{frame}
\begin{frame}{Визуализиурем модель}
    \begin{figure}
        \centering
        \includegraphics[width=\linewidth]{img/graphviz-model-simple}
        \caption{Визуализация модели в Graphviz}
    \end{figure}
\end{frame}
\begin{frame}{Априорное предиктивное распределение}
    Подобрать априорное распределение $\beta$ было несложно. А для $A_{g=0}$?
    \begin{itemize}
        \item<2-> Нет никакой информацией об априорном распределении
        \item<3-> Но кое-что знаем про $Y$
        \item<4-> $Y$ положительно, соответственно $A$ тоже положительно
        \item<5-> Есть наблюдаемые значения для $Y$, значит можно вывести значения для $A$?
        \item<6-> Степени 10 подойдут как значения для $Y$
        \item<7-> Для проверки -- построим априорное предиктивное распределение
    \end{itemize}
    \visible<8->{
    \begin{block}{Определение}
    Априорное предиктивное распределение строится как симуляция распределения без учета данных. 
    \end{block}
    \begin{alertblock}{Горькая правда}
    Подбор априорных распределений -- основа нашей непростой работы
    \end{alertblock}
    }
\end{frame}
\begin{frame}{Подбор распределения ''наобум''}
\begin{columns}
\begin{column}{0.5\linewidth}
Почему бы не предположить, например
\begin{equation*}
    A \sim \operatorname{LogNormal}(0, 1)
\end{equation*}
\visible<2->{
\begin{alertblock}{Контринтуитивный результат}
Никакой работник не пошьет вручную 800 ковров за неделю
\end{alertblock}}
\end{column}
\begin{column}{0.5\linewidth}
\visible<2->{Потому что (см. график ниже)
\begin{figure}
   \centering
   \includegraphics[width=\linewidth]{img/prior-predictive-cobb-douglas}
   \caption{Априорное предиктивное распределение Y и распределение реальных значений}
\end{figure}}
\end{column}
\end{columns}
\end{frame}
\section{Проверка априорного предиктивного распределения}
\begin{frame}{Анализируем априорные предиктивные распределения}
    \begin{columns}
\begin{column}{0.6\linewidth}
Еще раз вглянем на нашу модель 
\begin{align*}
    \log Y_{g=0} &\sim \operatorname{Normal}(\log A_{g=0} + \log L \cdot \beta, \eps)\\
    \eps &\sim \operatorname{LogNormal}(-2, 1)\\
    \beta &\sim \operatorname{LogitNormal}(0, 1)\\
    A_{g=0} &\sim \operatorname{LogNormal}(0, 1)
\end{align*}
\begin{itemize}
    \item Наблюдаем избыточную дисперсию
    \item Она может возникать из-за $A$ или $\eps$
\end{itemize}
\begin{block}{Что делать?}
\begin{enumerate}
    \item Попробуем уменьшить дисперсию $A$ 
    \item Попробуем уменьшить дисперсию $\eps$ 
\end{enumerate}
\end{block}
\end{column}
\begin{column}{0.4\linewidth}
Что получаем 
\begin{figure}
   \centering
   \includegraphics[width=\linewidth]{img/prior-predictive-cobb-douglas}
   \caption{Априорное предиктивное распределение Y и распределение реальных значений}
\end{figure}
\end{column}
\end{columns}
\end{frame}
\begin{frame}{Пример хорошего априорного предиктивного распределения}
\begin{columns}
    \begin{column}{0.6\linewidth}
    \begin{block}{На семинаре}
    Разберем схожий пример на семинаре.
    \end{block}
    Хорошее априорное предиктивное можно задать следующим образом:
    \begin{align*}
        \log Y_{g=0} &\sim \operatorname{Normal}(\log A_{g=0} + \log L \cdot \beta, \eps)\\
        \eps &\sim \operatorname{LogNormal}(-2, 0.1)\\
        \beta &\sim \operatorname{LogitNormal}(0, 1)\\
        A_{g=0} &\sim \operatorname{LogNormal}(-0.5, 0.1)\\
    \end{align*}
    \end{column}
    \begin{column}{0.4\linewidth}
    \begin{figure}
        \centering
        \includegraphics[width=\linewidth]{img/prior-predictive-cobb-douglas-good}
        \caption{Априорное предиктивное распределение Y и распределение реальных значений}
    \end{figure}
    \end{column}
\end{columns}
\end{frame}
\begin{frame}{Как понять, что априорное предиктивное распределение удачное?}
\begin{columns}
\begin{column}{0.6\linewidth}
\begin{itemize}
    \item  Распределение \textbf{достаточно} соответствует данным.
    \visible<2->{
    \begin{itemize}
        \item нет астрономических скоростей
        \item нет маленьких расстояний
        \item нет очень больших расстояний
        \item нет работников-стахановцев
    \end{itemize}
    }
    \item \textbf{Данные -- ориентир}, не самоцель
    \visible<3->{%
    \begin{itemize}
        \item не стоит подгонять распределение точь в точь под данные
        \item в 90\% данные не нужны
        \item в 90\% достаточно здравого смысла
        \item в 10\% можно спросить у экспертов
        \item смотреть на данные -- крайняя мера
    \end{itemize}
    }
\end{itemize}
\end{column}
\begin{column}{0.4\linewidth}
\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{img/prior-predictive-cobb-douglas-good}
    \caption{Априорное предиктивное распределение Y и распределение реальных значений}
\end{figure}
\end{column}
\end{columns}
\end{frame}
\begin{frame}{Пора применять HMC}
    \centering\includegraphics[width=0.5\linewidth]{img/big-red-button}
\end{frame}
\begin{frame}{Сэмплирование}
\begin{columns}
\begin{column}{0.3\linewidth}
 После всех проведенных проверок -- можно начинать сэмплирование.
\end{column}
\begin{column}{0.7\linewidth}
\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{img/example-cobb-douglas-trace}
    \caption{Апострериорное распределение, полученное MCMC}
\end{figure}
\end{column}
\end{columns}
\end{frame}
\section{Иерархии}
\subsection{Введение}
\begin{frame}{}
    \centering \Huge Иерархии
\end{frame}
\begin{frame}{Иерархии}
В исходных данных есть группы. Как это учесть?
\begin{align*}
        \log Y_{\textbf{g}} &\sim \operatorname{Normal}(\log A_{\textbf{g}} + \log L \cdot \beta, \eps)\\
        \eps &\sim \operatorname{LogNormal}(-2, 0.1)\\
        \beta &\sim \operatorname{LogitNormal}(0, 1)\\
        A_{\textbf{g}} &\sim \text{???}\\
    \end{align*}
\end{frame}
\begin{frame}{Что такое иерархии?}
    \begin{block}{Иерархии}
    Если в данных есть похожие группы, значит есть иерархии.
    \end{block}
    Примеры:
    \begin{enumerate}
        \item Страны, Регионы
        \item Разделение пользователей по полу, возрасту и тд.
        \item Группы воздействия
        \item Временные эффекты
        \item Панельные данные
    \end{enumerate}
    \begin{block}{Наш пример}
    Рабочие делают разные ковры и обладают совокупной производительностью $A$
    \end{block}
\end{frame}
\begin{frame}{Как учитывать иерархии}
Классический эконометрический подход:
    \begin{enumerate}
        \item Если все группы независимы. \textbf{Регрессия пула}
\begin{equation*}
    y_{k,i} = \alpha + \beta x_{k,i} + \varepsilon_{i,k}
\end{equation*}
        \item Если в группах есть различия. 
        
        \textbf{Регрессия с фиксированными эффектами}
\begin{equation*}
    y_{k,i} = \alpha_{k} + \beta x_{k,i} + \varepsilon_{i,k}
\end{equation*}
        \item Разница между группами случайная, незначительная. 
        
        \textbf{Регрессия со случайными эффектами}
\begin{equation*}
    y_{k,i} = \alpha + \beta x_{k,i} + u_{k} + \varepsilon_{i,k}
\end{equation*}
    \end{enumerate}
Где
\begin{equation*}
    \E u_{k,i} = 0,\quad \E \varepsilon_{k,i} = 0
\end{equation*}
\end{frame}
\subsection{Байесовский подход}
\begin{frame}{Байесовский подход к иерархиям}
Перепишем уравнение
\begin{equation*}
    y_{k,i} = \alpha + \beta x_{k,i} + u_{k} + \varepsilon_{i,k}
\end{equation*}
Следующим образом
\begin{equation*}
    y_{k,i} = (\alpha + u_{k}) + \beta x_{k,i} + \varepsilon_{i,k}
\end{equation*}
\begin{itemize}
    \item $\alpha$ - среднее по выборке
    \item $\alpha_k = \alpha + u_k$ - среднее по группе
\end{itemize}
 Байесовский подход требует априорных распределений. Например
\begin{columns}
\begin{column}{0.5\linewidth}
\begin{align*}
    \alpha &\sim \operatorname{Normal}(\bar\mu, \bar\sigma)\\
    u_k &\sim \operatorname{Normal}(0, 1)\\
    \alpha_k & = \alpha + u_k \cdot \sigma
\end{align*}
\end{column}
\begin{column}{0.5\linewidth}
\begin{align*}
    \alpha &\sim \operatorname{Normal}(\bar\mu, \bar\sigma)\\
    \alpha_k &\sim \operatorname{Normal}(\alpha, \sigma)
\end{align*}
\end{column}
\end{columns}
\end{frame}
\subsection{Параметризация}
\begin{frame}{Больше про априорные распределения}
\begin{columns}[t]
\begin{column}{0.5\linewidth}
Нецентрированная параметризация
\begin{align*}
    \alpha &\sim \operatorname{Normal}(\bar\mu, \bar\sigma)\\
    u_k &\sim \operatorname{Normal}(0, 1)\\
    \alpha_k & = \alpha + u_k \cdot \sigma
\end{align*}
Group specific parameter $u_k$ is disentangled
\end{column}
\begin{column}{0.5\linewidth}
Центрированная параметризация
\begin{align*}
    \alpha &\sim \operatorname{Normal}(\bar\mu, \bar\sigma)\\
    \alpha_k &\sim \operatorname{Normal}(\alpha, \sigma)
\end{align*}
\end{column}
\end{columns}
\vspace{1em}
$\sigma$ отражает разницу между группами
\begin{enumerate}
    \item $\sigma \to 0$: Модель пула
    \item Небольшая $\sigma$: Случайные эффекты / Частичный пул
    \item Большая $\sigma$: Фиксированные эффекты / Необъединенная модель
\end{enumerate}
$\sigma$ присутствует в каждом типе моделей
\end{frame}

\begin{frame}{Деградация моделей}
    \begin{columns}
    \begin{column}{0.5\linewidth}
    Для центрированной параметризации имеем
\begin{align*}
    \alpha &\sim \operatorname{Normal}(\bar\mu, \bar\sigma)\\
    \alpha_k &\sim \operatorname{Normal}(\alpha, \sigma)
\end{align*}
\begin{alertblock}{Предупреждение}
Для малого объема данных центрирование приводит к появлению воронок
\end{alertblock}
    \end{column}
    \begin{column}{0.5\linewidth}
    \begin{figure}
        \centering
        \includegraphics[width=\linewidth]{img/funnel}
        \caption{Центрирование и расхождения}
        \label{fig:my_label}
    \end{figure}
    \end{column}
    \end{columns}
\end{frame}
\begin{frame}{Как появляются воронки?}
    \begin{columns}
    \begin{column}{0.5\linewidth}
    Геометрия распределения имеет значение
    \begin{enumerate}
        \item При сэмплировании шаг учитывает предыдущие итерации
        \item При неудачно выбранном распределении сэмплеру сложно предсказать следующий шаг
    \end{enumerate}
    \end{column}
    \begin{column}{0.5\linewidth}
    \begin{figure}
        \centering
        \includegraphics[width=0.9\linewidth]{img/funnel_1}
        \caption{Пример воронки}
    \end{figure}
    \end{column}
    \end{columns}
\begin{block}{Рекомендация}
Про репараметризацию можно почитать \href{https://mc-stan.org/docs/2_18/stan-users-guide/reparameterization-section.html}{здесь}
\end{block}
\end{frame}
\begin{frame}{Инвертированная воронкообразная деградация}
    ''Удачная'' параметризация тоже имеет свои особенности
    \begin{figure}
        \centering
        \includegraphics[width=0.55\linewidth]{img/inverted_funnel}
        \caption{Пример инвертированной воронкообразной деградации}
    \end{figure}
\begin{alertblock}{Для дальнейшего погружения}
Почитать про это можно \href{https://betanalpha.github.io/assets/case_studies/hierarchical_modeling.html}{здесь}
\end{alertblock}
\end{frame}
\subsection{Априорные распределения}
\begin{frame}{Настраиваем иерархии в априорных распределениях}
    \begin{enumerate}
        \item Начать лучше с модели с одной группой или модели пула
        \visible<2->{
        \begin{itemize}
            \item Понимаем размерность и особенности параметров
            \item Структурируем модель
            \item Пока не думаем о предсказательной способности модели
        \end{itemize}
        }
        \item Добавляем иерархии
        \visible<3->{
        \begin{itemize}
            \item Выбираем параметр, для которого реализуем иерархии
            \item Выбираем, допустима ли вариативность остальных параметров
            \item Поправляем дивергенции, если нужно -- повторно подбираем параметры
        \end{itemize}
        }
    \end{enumerate}
\visible<4>{
\begin{block}{Практический совет}
Не надо хардокдить параметризацию, делайте свой код гибким
\end{block}
}
\end{frame}
\begin{frame}{Пример функции Кобба-Дугласа}
    \begin{columns}[t]
    \begin{column}{0.5\linewidth}
    Модель с единственной группой
     \begin{align*}
        \log Y_0 &\sim \operatorname{Normal}(\log A_0 + \log L \cdot \beta, \eps)\\
        \eps &\sim \operatorname{LogNormal}(-2, 0.1)\\
        \beta &\sim \operatorname{LogitNormal}(0, 1)\\
        A_0 &\sim \operatorname{LogNormal}(-0.5, 0.1)\\
    \end{align*}
    \end{column}
    \begin{column}{0.5\linewidth}
    Иерархическая модель
    \begin{align*}
        \log Y_k &\sim \operatorname{Normal}(\log A_k + \log L \cdot \beta, \eps)\\
        \eps &\sim \operatorname{LogNormal}(-2, 0.1)\\
        \beta &\sim \operatorname{LogitNormal}(0, 1)\\
        A_k &\sim \operatorname{LogNormal}(\alert<2>{\log A_{\text{pop}}}, \alert<2>{\sigma_A})\\
        \alert<2>{A_{\text{pop}}}&\alert<2>{\sim \operatorname{LogNormal}(-0.5, 0.1)}\\
        \alert<2>{\sigma_A}&\alert<2>{\sim \operatorname{LogNormal}(-2, 0.1)}
    \end{align*}
    \end{column}
    \end{columns}
\visible<2>{
\begin{block}{Подсказка}
Некоторые параметры можно переиспользовать, нужно лишь добавить немного вариативности с помощью $\sigma_A$
\end{block}
}
\end{frame}
\section{Обсуждение}
\begin{frame}{Обсуждаем итоги}
При подборе априорных распределений стоит помнить следующее
    \begin{itemize}
        \item Не всегда доступны экспертные знания
        \item Параметризация не всегда помогает подобрать хорошие распределения
        \item Иногда априорные предиктивные распределения зависят от многих параметров
        \item Вы часто скованы временем
        \item Можно применять гипераприорные распределения
    \end{itemize}
\end{frame}
\end{document}
